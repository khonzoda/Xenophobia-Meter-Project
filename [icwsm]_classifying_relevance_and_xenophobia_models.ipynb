{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda80a8a-8b3e-475f-bde0-03a85e4896ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e7b73e-9704-461f-acd8-5772731e8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_word_vectors.pickle', 'rb') as f:\n",
    "    unique_word_vectors = pickle.load(f)\n",
    "\n",
    "with open('agg_tweet_ratings.json') as f:\n",
    "    agg_tweet_ratings = json.load(f)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a77ee6-0d36-44f3-8f73-04a03d8f0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [128, 101, 77, 34, 255, 67, 195, 3, 222, 234]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663734c-776c-46b1-8d99-543e12662ea1",
   "metadata": {},
   "source": [
    "# Get vocabulary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ef94b-d2cf-4e4e-8c18-b1a82df60495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c14fb-a482-48bf-8a2f-dc8897ee7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6bb59-0419-480a-91b5-518da6c8c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('agg_tweet_ratings.json') as f:\n",
    "    agg_tweet_ratings = json.load(f)['data']\n",
    "\n",
    "unique_word_vectors = {}\n",
    "for tweet in agg_tweet_ratings:\n",
    "    clean_text = tweet['clean_text']\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    for word in tokens:\n",
    "        if word not in unique_word_vectors:\n",
    "            if word in glove_vectors:\n",
    "                unique_word_vectors[word] = glove_vectors[word]\n",
    "            else:\n",
    "                unique_word_vectors[word] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557f668-8caf-4b3e-b11d-cbf4a6ae751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('unique_word_vectors.pickle', 'wb') as f:\n",
    "    pickle.dump(unique_word_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad962a-6dec-4d7c-a085-3ccabb03235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([elt for elt in unique_word_vectors if unique_word_vectors[elt] is not None]), len(unique_word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819670e-2b44-4f99-a4f0-0927cce081a8",
   "metadata": {},
   "source": [
    "# Classifying Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82614ff7-8fc3-4576-b3ad-4cc17c0b94d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6939"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for tweet in agg_tweet_ratings:\n",
    "    clean_text = tweet['clean_text']\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    tweet_vectors = []\n",
    "    for word in tokens:\n",
    "        if unique_word_vectors[word] is not None:\n",
    "            tweet_vectors.append(unique_word_vectors[word])\n",
    "    if len(tweet_vectors)>0:\n",
    "        X.append(np.sum(tweet_vectors, axis=0))\n",
    "        y.append(tweet['relevance_rating'])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8a17f8-0f72-4fba-9216-92bfa2b9cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(seed):\n",
    "    scores = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                     random_state=seed)\n",
    "    \n",
    "    mlp_clf = MLPClassifier(random_state=seed, max_iter=500).fit(X_train, y_train)\n",
    "    y_pred = mlp_clf.predict(X_test)\n",
    "    scores['mlp_f1'] = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    log_reg_clf = LogisticRegression(random_state=seed, solver='liblinear', max_iter=300).fit(X_train, y_train)\n",
    "    y_pred = log_reg_clf.predict(X_test)\n",
    "    scores['log_reg_f1'] = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    svm_clf = svm.SVC(random_state=seed)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    scores['svm_f1'] = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ff7f87-5920-48bf-b074-f288a778c1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:10<00:00,  7.05s/it]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for seed in tqdm(random_seeds):\n",
    "    all_scores.append(run_models(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e65ab3-717d-4f22-aab9-2aa3ce718676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_f1 0.766 0.011\n",
      "mlp_f1 0.756 0.013\n",
      "svm_f1 0.754 0.011\n"
     ]
    }
   ],
   "source": [
    "log_reg_scores = [elt['log_reg_f1'] for elt in all_scores]\n",
    "print('log_reg_f1', round(sum(log_reg_scores)/len(log_reg_scores), 3), round(statistics.stdev(log_reg_scores),3))\n",
    "mlp_scores = [elt['mlp_f1'] for elt in all_scores]\n",
    "print('mlp_f1', round(sum(mlp_scores)/len(mlp_scores), 3), round(statistics.stdev(mlp_scores), 3))\n",
    "svm_scores = [elt['svm_f1'] for elt in all_scores]\n",
    "print('svm_f1', round(sum(svm_scores)/len(svm_scores), 3), round(statistics.stdev(svm_scores), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867397f-d6fa-4d7e-bcfb-80acce4ba6f6",
   "metadata": {},
   "source": [
    "# Classifying Xenophobia (3-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257753f6-623f-4739-bc30-5c4b1790b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colapse_to_three_categories(r):\n",
    "    if r < 0:\n",
    "        return 0\n",
    "    elif r > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34e94df-390a-484a-ae6c-aca3e7e02869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for tweet in agg_tweet_ratings:\n",
    "    if tweet['relevance_rating']:\n",
    "        clean_text = tweet['clean_text']\n",
    "        tokens = word_tokenize(clean_text)\n",
    "        tweet_vectors = []\n",
    "        for word in tokens:\n",
    "            if unique_word_vectors[word] is not None:\n",
    "                tweet_vectors.append(unique_word_vectors[word])\n",
    "        if len(tweet_vectors)>0:\n",
    "            X.append(np.sum(tweet_vectors, axis=0))\n",
    "            y.append(colapse_to_three_categories(tweet['xm_rating']))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93273b88-6785-4fc1-836e-0f924d83c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(seed):\n",
    "    scores = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                     random_state=seed)\n",
    "\n",
    "    # print('training Logistic Regression Classifier')\n",
    "    log_reg_clf = LogisticRegression(random_state=seed, solver='newton-cholesky', max_iter=300).fit(X_train, y_train)\n",
    "    # log_reg_clf = LogisticRegression(random_state=seed, solver='lbfgs', max_iter=300).fit(X_train, y_train)\n",
    "    scores['log_reg_acc'] = log_reg_clf.score(X_test, y_test)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c360abd-d173-458d-be17-106cf367882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 19.22it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for seed in tqdm(random_seeds):\n",
    "    all_scores.append(run_models(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff46cd8-a366-498f-b36d-8a83029b68c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_acc 0.811 0.007\n"
     ]
    }
   ],
   "source": [
    "log_reg_scores = [elt['log_reg_acc'] for elt in all_scores]\n",
    "print('log_reg_acc', round(sum(log_reg_scores)/len(log_reg_scores), 3), round(statistics.stdev(log_reg_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf3935-abf8-49dc-9832-467288cd13ce",
   "metadata": {},
   "source": [
    "# Classifying Xenophobia (7-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a780b6fe-41f7-4a06-9bbd-c01f78d38f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "z = []\n",
    "for tweet in agg_tweet_ratings:\n",
    "    if tweet['relevance_rating']:\n",
    "        clean_text = tweet['clean_text']\n",
    "        tokens = word_tokenize(clean_text)\n",
    "        tweet_vectors = []\n",
    "        for word in tokens:\n",
    "            if unique_word_vectors[word] is not None:\n",
    "                tweet_vectors.append(unique_word_vectors[word])\n",
    "        if len(tweet_vectors)>0:\n",
    "            X.append(np.sum(tweet_vectors, axis=0))\n",
    "            y.append(round(tweet['xm_rating']))\n",
    "            z.append(tweet['xm_rating'])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3456e6f6-eb85-4b62-be6f-de53be917261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(seed):\n",
    "    scores = {}\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, #stratify=z,\n",
    "                                                     random_state=seed)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=z,\n",
    "                                                     random_state=seed)\n",
    "    \n",
    "    lin_reg = LinearRegression().fit(X_train, z_train)\n",
    "    scores['lin_reg_acc'] = lin_reg.score(X_test, z_test)\n",
    "\n",
    "    ridge_reg = Ridge(alpha=1.0, solver='sag', random_state=seed, max_iter=300).fit(X_train, z_train)\n",
    "    scores['rigde_reg_acc'] = ridge_reg.score(X_test, z_test)\n",
    "\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=7)\n",
    "    knn_reg.fit(X_train, z_train)\n",
    "    scores['knn_reg_acc'] = knn_reg.score(X_test, z_test)\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=7)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    scores['knn_clf_acc'] = knn_clf.score(X_test, y_test)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36baf192-f006-49f0-99c5-a98599e0a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for seed in tqdm(random_seeds):\n",
    "    all_scores.append(run_models(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf6d708-2621-4f31-9a45-3b2896c53f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_reg_acc 0.416 0.017\n",
      "rigde_reg_acc 0.416 0.017\n",
      "knn_reg_acc 0.426 0.02\n",
      "knn_clf_acc 0.445 0.01\n"
     ]
    }
   ],
   "source": [
    "lin_reg_scores = [elt['lin_reg_acc'] for elt in all_scores]\n",
    "print('lin_reg_acc', round(sum(lin_reg_scores)/len(lin_reg_scores), 3), round(statistics.stdev(lin_reg_scores),3))\n",
    "rigde_reg_scores = [elt['rigde_reg_acc'] for elt in all_scores]\n",
    "print('rigde_reg_acc', round(sum(rigde_reg_scores)/len(rigde_reg_scores), 3), round(statistics.stdev(rigde_reg_scores), 3))\n",
    "knn_reg_scores = [elt['knn_reg_acc'] for elt in all_scores]\n",
    "print('knn_reg_acc', round(sum(knn_reg_scores)/len(knn_reg_scores), 3), round(statistics.stdev(knn_reg_scores), 3))\n",
    "knn_clf_scores = [elt['knn_clf_acc'] for elt in all_scores]\n",
    "print('knn_clf_acc', round(sum(knn_clf_scores)/len(knn_clf_scores), 3), round(statistics.stdev(knn_clf_scores), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37e74c-26d2-433a-a57e-b94e7b6be485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
